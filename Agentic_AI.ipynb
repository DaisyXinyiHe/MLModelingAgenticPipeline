{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s1aM_WBJWdtb",
    "outputId": "198fc837-45b0-47e2-9f95-e4f8f4acfb22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-agents\n",
      "  Downloading openai_agents-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting griffe<2,>=1.5.6 (from openai-agents)\n",
      "  Downloading griffe-1.15.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: mcp<2,>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (1.22.0)\n",
      "Requirement already satisfied: openai<3,>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (2.8.1)\n",
      "Requirement already satisfied: pydantic<3,>=2.12.3 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (2.12.3)\n",
      "Requirement already satisfied: requests<3,>=2.0 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (2.32.4)\n",
      "Collecting types-requests<3,>=2.0 (from openai-agents)\n",
      "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from openai-agents) (4.15.0)\n",
      "Collecting colorama>=0.4 (from griffe<2,>=1.5.6->openai-agents)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: anyio>=4.5 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.11.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.4.3)\n",
      "Requirement already satisfied: httpx>=0.27.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (2.12.0)\n",
      "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (3.0.3)\n",
      "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.48.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp<2,>=1.11.0->openai-agents) (0.38.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3,>=2.8.0->openai-agents) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3,>=2.8.0->openai-agents) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3,>=2.8.0->openai-agents) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3,>=2.8.0->openai-agents) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.12.3->openai-agents) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.12.3->openai-agents) (2.41.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0->openai-agents) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2,>=1.11.0->openai-agents) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp<2,>=1.11.0->openai-agents) (0.29.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp<2,>=1.11.0->openai-agents) (1.2.1)\n",
      "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents) (43.0.3)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp<2,>=1.11.0->openai-agents) (8.3.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp<2,>=1.11.0->openai-agents) (2.23)\n",
      "Downloading openai_agents-0.6.1-py3-none-any.whl (237 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.6/237.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading griffe-1.15.0-py3-none-any.whl (150 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: types-requests, colorama, griffe, openai-agents\n",
      "Successfully installed colorama-0.4.6 griffe-1.15.0 openai-agents-0.6.1 types-requests-2.32.4.20250913\n"
     ]
    }
   ],
   "source": [
    "!pip install openai-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJSbRxBwsZT9",
    "outputId": "8bc289e2-0308-4be7-fa60-15424f9a672b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "from google.colab import drive\n",
    "\n",
    "drive_mount_path = userdata.get('drive_mount_path')\n",
    "drive.mount(drive_mount_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ad3b945c"
   },
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Xmnt4jqAqMnN"
   },
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, FileSearchTool, WebSearchTool,ModelSettings\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "G6MKSJ8Yb7bE"
   },
   "outputs": [],
   "source": [
    "## EDA Agent\n",
    "## --- Conduct exploratory data analysis based on available data.\n",
    "## Decide what variable to use and feature engineering.\n",
    "## --- Available data are in csv format\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# class feature_analysis_result(BaseModel):\n",
    "#   likely_targets:list[str]\n",
    "#   selected_features:list[str]\n",
    "#   feature_engineering:list[str]\n",
    "#   drop_columns:list[str]\n",
    "#   missing_value_handling:AgentOutputSchema(dict, strict_json_schema=False)\n",
    "\n",
    "class feature_analysis_Agent:\n",
    "\n",
    "  '''\n",
    "  ## Feature Analysis Agent\n",
    "  ## --- Conduct exploratory data analysis based on available data.\n",
    "  ## Decide what variable to use and feature engineering.\n",
    "  ## --- Available data are in csv format\n",
    "\n",
    "  '''\n",
    "\n",
    "  def __init__(self, model:str = 'gpt-4o', user_instructions = '', user_defined_target = ''):\n",
    "    self.model = model\n",
    "    self.name = 'Feature Analysis Agent'\n",
    "    self.user_defined_target = user_defined_target\n",
    "    self.user_instructions = 'You are a data scientist specialized in feature analysis.\\\n",
    "    You analyze data, gives helpful insights on what variable to use and feature engineering.\\\n",
    "    Then you write code to apply your feature engineering suggesions and transform the dataset. '+user_instructions\n",
    "    if self.user_defined_target:\n",
    "      self.user_instructions += f'The target variable is {self.user_defined_target}'\n",
    "    self.agent = Agent(\n",
    "        name = self.name,\n",
    "        model = self.model,\n",
    "        instructions = self.user_instructions,\n",
    "        model_settings = ModelSettings(temperature = 0),\n",
    "        # output_type = feature_analysis_result\n",
    "        )\n",
    "\n",
    "  async def run(self, csv_path: str, varb_info_path:str=False):\n",
    "    df = self._load_csv(csv_path)\n",
    "    profile = self._profile_data(df)\n",
    "    suggestions = await self._llm_interpretation(profile, varb_info_path)\n",
    "    return {\n",
    "        'raw_profile':profile,\n",
    "        'Feature_analysis_suggestions':suggestions}\n",
    "\n",
    "  def _load_csv(self, csv_path:str):\n",
    "    '''load data'''\n",
    "    df = pd.read_csv(csv_path)\n",
    "    return df\n",
    "\n",
    "  def _profile_data(self, df:pd.DataFrame):\n",
    "    '''Check dataset profile, such as missing %, dtype, unique counts, etc'''\n",
    "    profile = {}\n",
    "    profile['n_rows'] = len(df)\n",
    "    profile['n_cols'] = len(df.columns)\n",
    "\n",
    "    ## Check dtype, missing %,\n",
    "    col_info = df.describe().to_dict()\n",
    "    for i in df.columns:\n",
    "      col_info[i]['missing_pct'] = 1 - col_info[i]['count']/len(df)\n",
    "      col_info[i]['dtype'] = str(df[i].dtype)\n",
    "      col_info[i]['unique_count'] = len(df[i].unique())\n",
    "\n",
    "    profile['col_info'] = col_info\n",
    "\n",
    "    return profile\n",
    "\n",
    "  async def _llm_interpretation(self, profile_dict, varb_info_path = False):\n",
    "    '''\n",
    "    Sends data summary and variable information if any to LLM\n",
    "    '''\n",
    "    if varb_info_path:\n",
    "      with open(varb_info_path, 'r') as file:\n",
    "        varb_info = file.read()\n",
    "    else:\n",
    "      varb_info = 'None'\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Given the following dataset profile:\n",
    "    {json.dumps(profile_dict, indent = 2)}\n",
    "    and the variable information below:\n",
    "    {varb_info}\n",
    "\n",
    "    Please :\n",
    "    1. Identify likely target variable if no target provided in instructions; otherwise, use the provided target\n",
    "    2. Identify useful predictor features\n",
    "    3. Identify columns to drop and reasoning\n",
    "    4. Suggest feature engineering (e.g. log transform, bucketization). \\\n",
    "    Any columns identified as 'drop columns' should not be selected for feature engineering.\n",
    "    5. Summarize missing variable issues and solutions\n",
    "\n",
    "    Return JSON structured as:\n",
    "    {{\n",
    "      'likely_targets':[],\n",
    "      'selected_features':[],\n",
    "      'drop_columns':[{{'Feature','Reason'}}],\n",
    "      'feature_engineering':[{{'Feature','Method','Reason'}}],\n",
    "      'missing_value_handling':[{{'Feature','Method','Reason'}}]\n",
    "\n",
    "    }}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    result = await Runner.run(self.agent, prompt)\n",
    "    print(result.final_output)\n",
    "    return result.final_output\n",
    "\n",
    "  async def generate_transformation_code(self, df_profile, suggestions):\n",
    "    \"\"\"\n",
    "    Based on suggestions, write code to transform data.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following:\n",
    "    Data Profile:\\n{json.dumps(df_profile, indent = 2)},\n",
    "    Data Transformation Suggestions:\\n{json.dumps(suggestions, indent = 2)},\n",
    "\n",
    "    Write python code that:\n",
    "    1. The dataset is called 'df'. Do not change the name of the dataset. Do not \\\n",
    "    read additional data.\n",
    "    2. Applies suggested transformations from Suggestions\n",
    "    3. return the transformed data in a pandas dataframe format as 'df_transformed'\n",
    "\n",
    "    Only return python code. No explanation.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    result = await Runner.run(self.agent, prompt)\n",
    "    # print(result.final_output)\n",
    "    return result.final_output\n",
    "\n",
    "  def execute_code(self, csv_path: str,  code:str):\n",
    "    '''Executes generated code and return df_transformed'''\n",
    "    df = pd.read_csv(csv_path)\n",
    "    local_varbs = {'df':df.copy(), 'pd':pd, 'np': np}\n",
    "    code = code.replace(\"```\", \"\")\n",
    "    code = code.removeprefix(\"python\")\n",
    "    exec(code, {}, local_varbs)\n",
    "    df_transformed = local_varbs.get('df_transformed',None)\n",
    "\n",
    "    return df_transformed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9p1MtUB0qmAa"
   },
   "outputs": [],
   "source": [
    "# ## No target provided\n",
    "# csv_path = userdata.get('train_data_path')\n",
    "# varb_info_path=userdata.get('varb_info_path')\n",
    "# user_instructions = \"build a model that predicts excess returns and includes a betting strategy\\\n",
    "#  designed to outperform the S&P 500 while staying within a 120% volatility constraint. We’ll\\\n",
    "#   provide daily data that combines public market information with our proprietary dataset, giving\\\n",
    "#    you the raw material to uncover patterns most miss.\"\n",
    "# fea_agent = feature_analysis_Agent(user_instructions = user_instructions)\n",
    "# result = await fea_agent.run(csv_path = csv_path, varb_info_path=varb_info_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "b_Ira77i4U5g"
   },
   "outputs": [],
   "source": [
    "## target provided\n",
    "csv_path = userdata.get('train_data_path')\n",
    "varb_info_path=userdata.get('varb_info_path')\n",
    "user_instructions = \"build a model that predicts excess returns and includes a betting strategy\\\n",
    " designed to outperform the S&P 500 while staying within a 120% volatility constraint. We’ll\\\n",
    "  provide daily data that combines public market information with our proprietary dataset, giving\\\n",
    "   you the raw material to uncover patterns most miss.\"\n",
    "fea_agent = feature_analysis_Agent(user_instructions = user_instructions, user_defined_target='market_forward_excess_returns')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SSAdnihIYPie",
    "outputId": "e7422fae-8015-491d-ea09-e9a531fffc9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"likely_targets\": [\n",
      "    \"market_forward_excess_returns\"\n",
      "  ],\n",
      "  \"selected_features\": [\n",
      "    \"M*\", \"E*\", \"I*\", \"P*\", \"V*\", \"S*\", \"D*\"\n",
      "  ],\n",
      "  \"drop_columns\": [\n",
      "    {\n",
      "      \"Feature\": \"date_id\",\n",
      "      \"Reason\": \"Identifier with no predictive value\"\n",
      "    },\n",
      "    {\n",
      "      \"Feature\": \"forward_returns\",\n",
      "      \"Reason\": \"Not available in test set\"\n",
      "    },\n",
      "    {\n",
      "      \"Feature\": \"risk_free_rate\",\n",
      "      \"Reason\": \"Not available in test set\"\n",
      "    }\n",
      "  ],\n",
      "  \"feature_engineering\": [\n",
      "    {\n",
      "      \"Feature\": \"E*\",\n",
      "      \"Method\": \"Standardization\",\n",
      "      \"Reason\": \"Macro Economic features have different scales\"\n",
      "    },\n",
      "    {\n",
      "      \"Feature\": \"I*\",\n",
      "      \"Method\": \"Standardization\",\n",
      "      \"Reason\": \"Interest Rate features have different scales\"\n",
      "    },\n",
      "    {\n",
      "      \"Feature\": \"P*\",\n",
      "      \"Method\": \"Log Transform\",\n",
      "      \"Reason\": \"Price/Valuation features may have skewed distributions\"\n",
      "    },\n",
      "    {\n",
      "      \"Feature\": \"V*\",\n",
      "      \"Method\": \"Standardization\",\n",
      "      \"Reason\": \"Volatility features have different scales\"\n",
      "    },\n",
      "    {\n",
      "      \"Feature\": \"S*\",\n",
      "      \"Method\": \"Standardization\",\n",
      "      \"Reason\": \"Sentiment features have different scales\"\n",
      "    }\n",
      "  ],\n",
      "  \"missing_value_handling\": [\n",
      "    {\n",
      "      \"Feature\": \"E*\",\n",
      "      \"Method\": \"Imputation with Mean\",\n",
      "      \"Reason\": \"Missing values in macroeconomic data\"\n",
      "    },\n",
      "    {\n",
      "      \"Feature\": \"M*\",\n",
      "      \"Method\": \"Imputation with Mean\",\n",
      "      \"Reason\": \"Missing values in market dynamics data\"\n",
      "    },\n",
      "    {\n",
      "      \"Feature\": \"I*\",\n",
      "      \"Method\": \"Imputation with Mean\",\n",
      "      \"Reason\": \"Missing values in interest rate data\"\n",
      "    },\n",
      "    {\n",
      "      \"Feature\": \"P*\",\n",
      "      \"Method\": \"Imputation with Mean\",\n",
      "      \"Reason\": \"Missing values in price/valuation data\"\n",
      "    },\n",
      "    {\n",
      "      \"Feature\": \"V*\",\n",
      "      \"Method\": \"Imputation with Mean\",\n",
      "      \"Reason\": \"Missing values in volatility data\"\n",
      "    },\n",
      "    {\n",
      "      \"Feature\": \"S*\",\n",
      "      \"Method\": \"Imputation with Mean\",\n",
      "      \"Reason\": \"Missing values in sentiment data\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "fea_eng_result = await fea_agent.run(csv_path = csv_path, varb_info_path=varb_info_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "RrTdVRlwPpUA",
    "outputId": "29f5dabf-8337-4209-f9b8-f2a06f759f91"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'```json\\n{\\n  \"likely_targets\": [\\n    \"market_forward_excess_returns\"\\n  ],\\n  \"selected_features\": [\\n    \"M*\", \"E*\", \"I*\", \"P*\", \"V*\", \"S*\", \"D*\"\\n  ],\\n  \"drop_columns\": [\\n    {\\n      \"Feature\": \"date_id\",\\n      \"Reason\": \"Identifier with no predictive value\"\\n    },\\n    {\\n      \"Feature\": \"forward_returns\",\\n      \"Reason\": \"Not available in test set\"\\n    },\\n    {\\n      \"Feature\": \"risk_free_rate\",\\n      \"Reason\": \"Not available in test set\"\\n    }\\n  ],\\n  \"feature_engineering\": [\\n    {\\n      \"Feature\": \"E*\",\\n      \"Method\": \"Standardization\",\\n      \"Reason\": \"Macro Economic features have different scales\"\\n    },\\n    {\\n      \"Feature\": \"I*\",\\n      \"Method\": \"Standardization\",\\n      \"Reason\": \"Interest Rate features have different scales\"\\n    },\\n    {\\n      \"Feature\": \"P*\",\\n      \"Method\": \"Log Transform\",\\n      \"Reason\": \"Price/Valuation features may have skewed distributions\"\\n    },\\n    {\\n      \"Feature\": \"V*\",\\n      \"Method\": \"Standardization\",\\n      \"Reason\": \"Volatility features have different scales\"\\n    },\\n    {\\n      \"Feature\": \"S*\",\\n      \"Method\": \"Standardization\",\\n      \"Reason\": \"Sentiment features have different scales\"\\n    }\\n  ],\\n  \"missing_value_handling\": [\\n    {\\n      \"Feature\": \"E*\",\\n      \"Method\": \"Imputation with Mean\",\\n      \"Reason\": \"Missing values in macroeconomic data\"\\n    },\\n    {\\n      \"Feature\": \"M*\",\\n      \"Method\": \"Imputation with Mean\",\\n      \"Reason\": \"Missing values in market dynamics data\"\\n    },\\n    {\\n      \"Feature\": \"I*\",\\n      \"Method\": \"Imputation with Mean\",\\n      \"Reason\": \"Missing values in interest rate data\"\\n    },\\n    {\\n      \"Feature\": \"P*\",\\n      \"Method\": \"Imputation with Mean\",\\n      \"Reason\": \"Missing values in price/valuation data\"\\n    },\\n    {\\n      \"Feature\": \"V*\",\\n      \"Method\": \"Imputation with Mean\",\\n      \"Reason\": \"Missing values in volatility data\"\\n    },\\n    {\\n      \"Feature\": \"S*\",\\n      \"Method\": \"Imputation with Mean\",\\n      \"Reason\": \"Missing values in sentiment data\"\\n    }\\n  ]\\n}\\n```'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fea_eng_result['Feature_analysis_suggestions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tkP2_hTY3eM",
    "outputId": "be592c35-624d-4ccf-c937-dc133f82a545"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated code:\n",
      "```python\n",
      "import pandas as pd\n",
      "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
      "import numpy as np\n",
      "\n",
      "# Drop columns\n",
      "df = df.drop(columns=['date_id', 'forward_returns', 'risk_free_rate'])\n",
      "\n",
      "# Impute missing values with mean\n",
      "for col in df.columns:\n",
      "    if df[col].isnull().any():\n",
      "        df[col].fillna(df[col].mean(), inplace=True)\n",
      "\n",
      "# Standardization\n",
      "scaler = StandardScaler()\n",
      "for prefix in ['E', 'I', 'V', 'S']:\n",
      "    cols = [col for col in df.columns if col.startswith(prefix)]\n",
      "    df[cols] = scaler.fit_transform(df[cols])\n",
      "\n",
      "# Log Transform for P* features\n",
      "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
      "p_cols = [col for col in df.columns if col.startswith('P')]\n",
      "df[p_cols] = log_transformer.fit_transform(df[p_cols])\n",
      "\n",
      "# Return the transformed dataframe\n",
      "df_transformed = df\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "code = await fea_agent.generate_transformation_code(\n",
    "    fea_eng_result['raw_profile'],\n",
    "    fea_eng_result['Feature_analysis_suggestions']\n",
    ")\n",
    "\n",
    "print(\"Generated code:\")\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "O6UP3V0cY_wC",
    "outputId": "e55b64fd-fd42-46b1-c991-b2b46917d6ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/preprocessing/_function_transformer.py:387: RuntimeWarning: invalid value encountered in log1p\n",
      "  return func(X, **(kw_args if kw_args else {}))\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-e5f59a9c-2fe2-4f97-a044-37e71e8a1be8\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>E1</th>\n",
       "      <th>...</th>\n",
       "      <th>V13</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>market_forward_excess_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.912782e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.143207e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.923667e-16</td>\n",
       "      <td>-3.843260e-16</td>\n",
       "      <td>-5.277907e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.912782e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.143207e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.923667e-16</td>\n",
       "      <td>-3.843260e-16</td>\n",
       "      <td>-5.277907e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.912782e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.143207e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.923667e-16</td>\n",
       "      <td>-3.843260e-16</td>\n",
       "      <td>-5.277907e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.912782e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.143207e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.923667e-16</td>\n",
       "      <td>-3.843260e-16</td>\n",
       "      <td>-5.277907e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.912782e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.143207e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.923667e-16</td>\n",
       "      <td>-3.843260e-16</td>\n",
       "      <td>-5.277907e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.012301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5f59a9c-2fe2-4f97-a044-37e71e8a1be8')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-e5f59a9c-2fe2-4f97-a044-37e71e8a1be8 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-e5f59a9c-2fe2-4f97-a044-37e71e8a1be8');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    <div id=\"df-38906b7a-8e9e-4b8a-af7d-d0852dc3c9b1\">\n",
       "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38906b7a-8e9e-4b8a-af7d-d0852dc3c9b1')\"\n",
       "                title=\"Suggest charts\"\n",
       "                style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "      </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "      <script>\n",
       "        async function quickchart(key) {\n",
       "          const quickchartButtonEl =\n",
       "            document.querySelector('#' + key + ' button');\n",
       "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "          try {\n",
       "            const charts = await google.colab.kernel.invokeFunction(\n",
       "                'suggestCharts', [key], {});\n",
       "          } catch (error) {\n",
       "            console.error('Error during call to suggestCharts:', error);\n",
       "          }\n",
       "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "        }\n",
       "        (() => {\n",
       "          let quickchartButtonEl =\n",
       "            document.querySelector('#df-38906b7a-8e9e-4b8a-af7d-d0852dc3c9b1 button');\n",
       "          quickchartButtonEl.style.display =\n",
       "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "        })();\n",
       "      </script>\n",
       "    </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   D1  D2  D3  D4  D5  D6  D7  D8  D9            E1  ...           V13   V2  \\\n",
       "0   0   0   0   1   1   0   0   0   1 -3.912782e-16  ...  1.143207e-17  0.0   \n",
       "1   0   0   0   1   1   0   0   0   1 -3.912782e-16  ...  1.143207e-17  0.0   \n",
       "2   0   0   0   1   0   0   0   0   1 -3.912782e-16  ...  1.143207e-17  0.0   \n",
       "3   0   0   0   1   0   0   0   0   0 -3.912782e-16  ...  1.143207e-17  0.0   \n",
       "4   0   0   0   1   0   0   0   0   0 -3.912782e-16  ...  1.143207e-17  0.0   \n",
       "\n",
       "             V3            V4            V5   V6   V7   V8   V9  \\\n",
       "0  1.923667e-16 -3.843260e-16 -5.277907e-17  0.0  0.0  0.0  0.0   \n",
       "1  1.923667e-16 -3.843260e-16 -5.277907e-17  0.0  0.0  0.0  0.0   \n",
       "2  1.923667e-16 -3.843260e-16 -5.277907e-17  0.0  0.0  0.0  0.0   \n",
       "3  1.923667e-16 -3.843260e-16 -5.277907e-17  0.0  0.0  0.0  0.0   \n",
       "4  1.923667e-16 -3.843260e-16 -5.277907e-17  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   market_forward_excess_returns  \n",
       "0                      -0.003038  \n",
       "1                      -0.009114  \n",
       "2                      -0.010243  \n",
       "3                       0.004046  \n",
       "4                      -0.012301  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Execute to get transformed df\n",
    "import numpy as np\n",
    "csv_path = userdata.get('train_data_path')\n",
    "df_transformed = fea_agent.execute_code(csv_path = csv_path, code = code)\n",
    "\n",
    "display(df_transformed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "sgbiktfDwGZ_"
   },
   "outputs": [],
   "source": [
    "class ModelingAgent:\n",
    "\n",
    "  def __init__(self, model = 'gpt-4o',user_instructions = '', user_defined_target = ''):\n",
    "    self.model = model\n",
    "    self.name = 'Modeling Agent'\n",
    "    self.user_defined_target = user_defined_target\n",
    "    self.user_instructions = 'You are a data scientist specialized in machine learning modeling.\\\n",
    "    You take in problem statement, variable descriptions, transformed data based on the suggestions by the feature analysis agent, \\\n",
    "     and target variable(s). Based on these information, you make suggestions \\\n",
    "     on: \\\n",
    "     1. What kind of model we should build (e.g. Classification or regression)\\\n",
    "     2. What machine learning algorithm to use (e.g. linear regression,time series, XGBoost, or deep learning)\\\n",
    "     3. What hyperparameter we should tune\\\n",
    "      '+user_instructions\n",
    "\n",
    "    if self.user_defined_target:\n",
    "      self.user_instructions += f'The target variable is {self.user_defined_target}'\n",
    "\n",
    "    self.agent = Agent(\n",
    "        name = self.name,\n",
    "        model = self.model,\n",
    "        instructions = self.user_instructions,\n",
    "        model_settings = ModelSettings(temperature = 0)\n",
    "        )\n",
    "\n",
    "\n",
    "  async def proposed_model(self, problem_statement:str, varb_info_path:str,fea_eng_suggestions:str, df_transformed:pd.DataFrame, target_variable:str):\n",
    "\n",
    "    if varb_info_path:\n",
    "      with open(varb_info_path, 'r') as file:\n",
    "        original_varb_info = file.read()\n",
    "    else:\n",
    "      original_varb_info = 'None'\n",
    "\n",
    "\n",
    "    schema = {\n",
    "        'columns':list(df_transformed.columns),\n",
    "        'problem_statement':problem_statement,\n",
    "        'original_varb_info':original_varb_info,\n",
    "        'fea_eng_suggestions':fea_eng_suggestions,\n",
    "        'target_variable':target_variable\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are given:\n",
    "    * Problem Statement: {schema.get('problem_statement')}\n",
    "    * Original Variable Descriptions: {schema.get('original_varb_info')}\n",
    "    * Feature Engineering Suggestions: {schema.get('fea_eng_suggestions')}\n",
    "    * Transformed Data: {schema.get('columns')}\n",
    "    * Target Variable: {schema.get('target_variable')}\n",
    "\n",
    "    Tasks:\n",
    "    1. Determine whetehr problem is regression or classification\n",
    "    2. Select a machine learning model type\n",
    "    3. Recommend hyperparameters to tune on\n",
    "    4. Recommend evaluation protocol (cross validation or train/test split only)\n",
    "    5. If cross validation, recommend train/validation/test split ratio as 0.7:0.2:0.1. \\\n",
    "    If train/test split only, recommend train/test split ratio as 0.8:0.2.\n",
    "    6. Suggest metrics to evaluate model performance\n",
    "    7. Explain reasoning of the above decisions\n",
    "    8. Return JSON strictly:\n",
    "\n",
    "    {{\n",
    "      'target_variable':'{target_variable}',\n",
    "      'features':{str([x for x in list(df_transformed.columns) if x != target_variable])}.\n",
    "      'task_type':'regression'|'classification',\n",
    "      'model_type':'linear_regression'|'time_series'|'xgboost'|'deep_learning'|...,\n",
    "      'hyperparameters':'hyperparameter':'value',\n",
    "      'evaluation_protocol':'cross_validation'|'train_test_split_only',\n",
    "      'train_test_split_ratio':0.7:0.2:0.1 | 0.8:0.2,\n",
    "      'metrics':['metric1','metric2','metrics3'...],\n",
    "      'reasoning':'reasoning'\n",
    "\n",
    "\n",
    "    }}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    result = await Runner.run(self.agent, prompt)\n",
    "    print(result.final_output)\n",
    "    return result.final_output\n",
    "\n",
    "  async def generate_modeling_code(self, modeling_proposal:str,):\n",
    "    \"\"\"\n",
    "    Based on modeling_proposal, write code to train model and evaluate model performance.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Based on the following:\n",
    "    Modeling_proposal:\\n{json.dumps(modeling_proposal, indent = 2)},\n",
    "\n",
    "    Write python code that:\n",
    "    1. The dataset is called 'df_transformed'. Do not change the name of the dataset. Do not \\\n",
    "    read additional data.\n",
    "    2. Applies modeling proposal from Modeling_proposal\n",
    "    3. Write code to train model and evaluate model performance. \\\n",
    "        a. If you use 'early_stopping_rounds' as a parameter, pass it to the constructor of model.\n",
    "        b. Save training history\n",
    "    4. return model as 'Model',  evaluation result as 'evaluation_result':{{'metric1':float,'metric2':float...}}\\\n",
    "    training history as 'training_history'\n",
    "\n",
    "    Only return python code. No explanation.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    result = await Runner.run(self.agent, prompt)\n",
    "    print(result.final_output)\n",
    "    return result.final_output\n",
    "\n",
    "  async def execute_code(self, df_transformed: pd.DataFrame,  code:str):\n",
    "    '''Executes generated code and return model and result'''\n",
    "    local_varbs = {'df_transformed':df_transformed.copy(), 'pd':pd, 'np': np}\n",
    "    code = code.replace(\"```\", \"\")\n",
    "    code = code.removeprefix(\"python\")\n",
    "    try:\n",
    "      exec(code, {}, local_varbs)\n",
    "    except Exception as e:\n",
    "      prompt = f'''Receive this error: {e}. Fix the error in the original code.Original code: {code}. Only return python code. No explanation.'''\n",
    "      result = await Runner.run(self.agent, prompt)\n",
    "      print(f\"{prompt} \\n Error: {e} \\n Updated code: {result.final_output}\")\n",
    "      code = result.final_output\n",
    "      code = code.replace(\"```\", \"\")\n",
    "      code = code.removeprefix(\"python\")\n",
    "      exec(code, {}, local_varbs)\n",
    "\n",
    "    model = local_varbs.get('Model',None)\n",
    "    evaluation_result = local_varbs.get('evaluation_result',None)\n",
    "    training_history = local_varbs.get('training_history',None)\n",
    "\n",
    "    return model, evaluation_result,training_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_mrZROWeypK"
   },
   "outputs": [],
   "source": [
    "modeling_agent=ModelingAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SZAjZr6FR8m6"
   },
   "outputs": [],
   "source": [
    "problem_statement = \"build a model that predicts excess returns and includes a betting strategy\\\n",
    " designed to outperform the S&P 500 while staying within a 120% volatility constraint. We’ll\\\n",
    "  provide daily data that combines public market information with our proprietary dataset, giving\\\n",
    "   you the raw material to uncover patterns most miss.\"\n",
    "\n",
    "varb_info_path=userdata.get('varb_info_path')\n",
    "\n",
    "\n",
    "fea_eng_suggestions = fea_eng_result['Feature_analysis_suggestions']\n",
    "df_transformed = df_transformed.copy()\n",
    "target_variable = 'market_forward_excess_returns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jLC3Yx--RsZf",
    "outputId": "c4648f00-4bf3-43d0-9a50-e42528a9dc36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"target_variable\": \"market_forward_excess_returns\",\n",
      "  \"features\": [\n",
      "    \"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\", \"D7\", \"D8\", \"D9\", \"E1\", \"E10\", \"E11\", \"E12\", \"E13\", \"E14\", \"E15\", \"E16\", \"E17\", \"E18\", \"E19\", \"E2\", \"E20\", \"E3\", \"E4\", \"E5\", \"E6\", \"E7\", \"E8\", \"E9\", \"I1\", \"I2\", \"I3\", \"I4\", \"I5\", \"I6\", \"I7\", \"I8\", \"I9\", \"M1\", \"M10\", \"M11\", \"M12\", \"M13\", \"M14\", \"M15\", \"M16\", \"M17\", \"M18\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\", \"P1\", \"P10\", \"P11\", \"P12\", \"P13\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"P9\", \"S1\", \"S10\", \"S11\", \"S12\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\", \"S7\", \"S8\", \"S9\", \"V1\", \"V10\", \"V11\", \"V12\", \"V13\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\"\n",
      "  ],\n",
      "  \"task_type\": \"regression\",\n",
      "  \"model_type\": \"xgboost\",\n",
      "  \"hyperparameters\": {\n",
      "    \"n_estimators\": 100,\n",
      "    \"max_depth\": 6,\n",
      "    \"learning_rate\": 0.1,\n",
      "    \"subsample\": 0.8,\n",
      "    \"colsample_bytree\": 0.8\n",
      "  },\n",
      "  \"evaluation_protocol\": \"cross_validation\",\n",
      "  \"train_test_split_ratio\": \"0.7:0.2:0.1\",\n",
      "  \"metrics\": [\"mean_squared_error\", \"r2_score\"],\n",
      "  \"reasoning\": \"The problem is a regression task because we are predicting a continuous variable, 'market_forward_excess_returns'. XGBoost is chosen due to its robustness and ability to handle missing values and complex relationships. Hyperparameters like 'n_estimators', 'max_depth', and 'learning_rate' are crucial for controlling model complexity and learning. Cross-validation is recommended to ensure the model's generalizability, and a 0.7:0.2:0.1 split allows for a balanced evaluation. Metrics like mean squared error and r2_score are suitable for assessing regression model performance.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "model_proposal = await modeling_agent.proposed_model(problem_statement, varb_info_path,fea_eng_suggestions, df_transformed, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-LMR1Z9TSxG0"
   },
   "outputs": [],
   "source": [
    "# model_proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OwhwpP2VWWtD"
   },
   "outputs": [],
   "source": [
    "# df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vR1floAuS0VO",
    "outputId": "40f05e7c-ad95-48b4-bf99-236072d22dd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import xgboost as xgb\n",
      "from sklearn.model_selection import train_test_split, cross_val_score\n",
      "from sklearn.metrics import mean_squared_error, r2_score\n",
      "import numpy as np\n",
      "\n",
      "# Define features and target\n",
      "X = df_transformed[[\n",
      "    \"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\", \"D7\", \"D8\", \"D9\", \"E1\", \"E10\", \"E11\", \"E12\", \"E13\", \"E14\", \"E15\", \"E16\", \"E17\", \"E18\", \"E19\", \"E2\", \"E20\", \"E3\", \"E4\", \"E5\", \"E6\", \"E7\", \"E8\", \"E9\", \"I1\", \"I2\", \"I3\", \"I4\", \"I5\", \"I6\", \"I7\", \"I8\", \"I9\", \"M1\", \"M10\", \"M11\", \"M12\", \"M13\", \"M14\", \"M15\", \"M16\", \"M17\", \"M18\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\", \"P1\", \"P10\", \"P11\", \"P12\", \"P13\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"P9\", \"S1\", \"S10\", \"S11\", \"S12\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\", \"S7\", \"S8\", \"S9\", \"V1\", \"V10\", \"V11\", \"V12\", \"V13\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\"\n",
      "]]\n",
      "y = df_transformed[\"market_forward_excess_returns\"]\n",
      "\n",
      "# Split the data\n",
      "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
      "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.333, random_state=42)\n",
      "\n",
      "# Define the model\n",
      "model = xgb.XGBRegressor(\n",
      "    n_estimators=100,\n",
      "    max_depth=6,\n",
      "    learning_rate=0.1,\n",
      "    subsample=0.8,\n",
      "    colsample_bytree=0.8,\n",
      "    early_stopping_rounds=10,\n",
      "    eval_metric=\"rmse\"\n",
      ")\n",
      "\n",
      "# Train the model\n",
      "eval_set = [(X_train, y_train), (X_val, y_val)]\n",
      "model.fit(X_train, y_train, eval_set=eval_set, verbose=False)\n",
      "\n",
      "# Save training history\n",
      "training_history = model.evals_result()\n",
      "\n",
      "# Evaluate the model\n",
      "y_pred = model.predict(X_test)\n",
      "mse = mean_squared_error(y_test, y_pred)\n",
      "r2 = r2_score(y_test, y_pred)\n",
      "\n",
      "# Return model, evaluation result, and training history\n",
      "Model = model\n",
      "evaluation_result = {'mean_squared_error': mse, 'r2_score': r2}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "modeling_code = await modeling_agent.generate_modeling_code(model_proposal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "dX6wkLodf_SE"
   },
   "outputs": [],
   "source": [
    "Model, evaluation_result,training_history = await modeling_agent.execute_code(df_transformed,  modeling_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jlZrwpUGgsR9",
    "outputId": "c1c239ee-25ba-479b-ca51-e9bd51f6e81a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_squared_error': 0.00012322073669942247,\n",
       " 'r2_score': 0.0012726051484519552}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oNYN_v0Apl0L",
    "outputId": "bd09f2f9-7bbc-43bc-ab78-f891414a22d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validation_0': OrderedDict([('rmse',\n",
       "               [0.01048529397134944,\n",
       "                0.0103840285095624,\n",
       "                0.01028961823970748,\n",
       "                0.01022318456637951,\n",
       "                0.01014926914552499,\n",
       "                0.01008554739715958,\n",
       "                0.01000718742916796,\n",
       "                0.00995404975029369,\n",
       "                0.00988796954583577,\n",
       "                0.00983949159071531,\n",
       "                0.00973796863132236])]),\n",
       " 'validation_1': OrderedDict([('rmse',\n",
       "               [0.01028114538201944,\n",
       "                0.01028993741031988,\n",
       "                0.01030893996021545,\n",
       "                0.01031392154295,\n",
       "                0.01030915006405261,\n",
       "                0.0103250057622733,\n",
       "                0.0103157590215059,\n",
       "                0.01031127311783293,\n",
       "                0.01031158683060553,\n",
       "                0.01030652924031971,\n",
       "                0.01029361956119773])])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "YlhxktHSgvuG"
   },
   "outputs": [],
   "source": [
    "## Build an evaluation agent\n",
    "\n",
    "\n",
    "class EvaluationAgent:\n",
    "\n",
    "  def __init__(self, model = 'gpt-4o',user_instructions = '', user_defined_target = ''):\n",
    "    self.model = model\n",
    "    self.name = 'Evaluation Agent'\n",
    "    self.user_defined_target = user_defined_target\n",
    "    self.user_instructions = 'You are a data scientist specialized in evaluating machine learning model.\\\n",
    "    You take in modeling proposal, training result, and training history.\\\n",
    "    Based on these information, you make suggestions on how to improve the model\\\n",
    "      '+user_instructions\n",
    "\n",
    "    if self.user_defined_target:\n",
    "      self.user_instructions += f'The target variable is {self.user_defined_target}'\n",
    "\n",
    "    self.agent = Agent(\n",
    "        name = self.name,\n",
    "        model = self.model,\n",
    "        instructions = self.user_instructions,\n",
    "        model_settings = ModelSettings(temperature = 0)\n",
    "        )\n",
    "\n",
    "\n",
    "  async def analyze_model(self, modeling_proposal:str, training_result:str,training_history:str):\n",
    "\n",
    "\n",
    "    schema = {\n",
    "        'modeling_proposal':modeling_proposal,\n",
    "        'training_result':training_result,\n",
    "        'training_history':training_history,\n",
    "        'target_variable':self.user_defined_target\n",
    "    }\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are given:\n",
    "    * Modeling Proposal: {schema.get('modeling_proposal')}\n",
    "    * Training Result: {schema.get('training_result')}\n",
    "    * Training History: {schema.get('training_history')}\n",
    "    * Target Variable: {schema.get('target_variable')}\n",
    "\n",
    "    Tasks:\n",
    "    1. Read Modeling Proposal\n",
    "    2. Examinate the training history and training result\n",
    "    3. Suggest method to improve the model\n",
    "    4. Explain reasoning of the above decisions\n",
    "    5. Return JSON strictly:\n",
    "\n",
    "    {{\n",
    "      'target_variable':'{self.user_defined_target }',\n",
    "      'modeling_proposal':{modeling_proposal}.\n",
    "      'training_result':{training_result},\n",
    "      'reasoning':'reasoning'\n",
    "\n",
    "\n",
    "    }}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    result = await Runner.run(self.agent, prompt)\n",
    "    print(result.final_output)\n",
    "    return result.final_output\n",
    "\n",
    "  # async def generate_modeling_code(self, modeling_proposal:str,):\n",
    "  #   \"\"\"\n",
    "  #   Based on modeling_proposal, write code to train model and evaluate model performance.\n",
    "  #   \"\"\"\n",
    "\n",
    "\n",
    "  #   prompt = f\"\"\"\n",
    "  #   Based on the following:\n",
    "  #   Modeling_proposal:\\n{json.dumps(modeling_proposal, indent = 2)},\n",
    "\n",
    "  #   Write python code that:\n",
    "  #   1. The dataset is called 'df_transformed'. Do not change the name of the dataset. Do not \\\n",
    "  #   read additional data.\n",
    "  #   2. Applies modeling proposal from Modeling_proposal\n",
    "  #   3. Write code to train model and evaluate model performance. \\\n",
    "  #   If you use 'early_stopping_rounds' as a parameter, pass it to the constructor of model.\n",
    "  #   4. return model as 'Model' and evaluation result as 'evaluation_result':{{'metric1':float,'metric2':float...}}\n",
    "\n",
    "  #   Only return python code. No explanation.\n",
    "  #   \"\"\"\n",
    "\n",
    "\n",
    "  #   result = await Runner.run(self.agent, prompt)\n",
    "  #   print(result.final_output)\n",
    "  #   return result.final_output\n",
    "\n",
    "  # def execute_code(self, df_transformed: pd.DataFrame,  code:str):\n",
    "  #   '''Executes generated code and return model and result'''\n",
    "  #   local_varbs = {'df_transformed':df_transformed.copy(), 'pd':pd, 'np': np}\n",
    "  #   code = code.replace(\"```\", \"\")\n",
    "  #   code = code.removeprefix(\"python\")\n",
    "  #   exec(code, {}, local_varbs)\n",
    "  #   model = local_varbs.get('Model',None)\n",
    "  #   evaluation_result = local_varbs.get('evaluation_result',None)\n",
    "\n",
    "  #   return model, evaluation_result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Od30f4InaXYH"
   },
   "outputs": [],
   "source": [
    "evaluation_agent = EvaluationAgent(user_instructions = problem_statement,user_defined_target =target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PdT__RfIaZ1X",
    "outputId": "e73b5231-3b38-4bb3-971a-921c264c6149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"target_variable\": \"market_forward_excess_returns\",\n",
      "  \"modeling_proposal\": {\n",
      "    \"target_variable\": \"market_forward_excess_returns\",\n",
      "    \"features\": [\n",
      "      \"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\", \"D7\", \"D8\", \"D9\", \"E1\", \"E10\", \"E11\", \"E12\", \"E13\", \"E14\", \"E15\", \"E16\", \"E17\", \"E18\", \"E19\", \"E2\", \"E20\", \"E3\", \"E4\", \"E5\", \"E6\", \"E7\", \"E8\", \"E9\", \"I1\", \"I2\", \"I3\", \"I4\", \"I5\", \"I6\", \"I7\", \"I8\", \"I9\", \"M1\", \"M10\", \"M11\", \"M12\", \"M13\", \"M14\", \"M15\", \"M16\", \"M17\", \"M18\", \"M2\", \"M3\", \"M4\", \"M5\", \"M6\", \"M7\", \"M8\", \"M9\", \"P1\", \"P10\", \"P11\", \"P12\", \"P13\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"P9\", \"S1\", \"S10\", \"S11\", \"S12\", \"S2\", \"S3\", \"S4\", \"S5\", \"S6\", \"S7\", \"S8\", \"S9\", \"V1\", \"V10\", \"V11\", \"V12\", \"V13\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\", \"V7\", \"V8\", \"V9\"\n",
      "    ],\n",
      "    \"task_type\": \"regression\",\n",
      "    \"model_type\": \"xgboost\",\n",
      "    \"hyperparameters\": {\n",
      "      \"n_estimators\": 100,\n",
      "      \"max_depth\": 6,\n",
      "      \"learning_rate\": 0.1,\n",
      "      \"subsample\": 0.8,\n",
      "      \"colsample_bytree\": 0.8\n",
      "    },\n",
      "    \"evaluation_protocol\": \"cross_validation\",\n",
      "    \"train_test_split_ratio\": \"0.7:0.2:0.1\",\n",
      "    \"metrics\": [\"mean_squared_error\", \"r2_score\"],\n",
      "    \"reasoning\": \"The problem is a regression task because we are predicting a continuous variable, 'market_forward_excess_returns'. XGBoost is chosen due to its robustness and ability to handle missing values and complex relationships. Hyperparameters like 'n_estimators', 'max_depth', and 'learning_rate' are crucial for controlling model complexity and learning. Cross-validation is recommended to ensure the model's generalizability, and a 0.7:0.2:0.1 split allows for a balanced evaluation. Metrics like mean squared error and r2_score are suitable for assessing regression model performance.\"\n",
      "  },\n",
      "  \"training_result\": {\n",
      "    \"mean_squared_error\": 0.00012322073669942247,\n",
      "    \"r2_score\": 0.0012726051484519552\n",
      "  },\n",
      "  \"reasoning\": \"The training results indicate a very low r2_score, suggesting that the model is not capturing the variance in the target variable effectively. The training history shows that the validation RMSE does not improve significantly, indicating potential overfitting or that the model is not learning effectively. To improve the model, consider the following: 1) Feature engineering to create more informative features. 2) Hyperparameter tuning, especially increasing 'n_estimators' and adjusting 'max_depth' and 'learning_rate'. 3) Try different model types like Random Forest or Neural Networks. 4) Use more advanced techniques like feature selection or dimensionality reduction to improve model performance.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "evaluator_suggestion = await evaluation_agent.analyze_model(model_proposal, evaluation_result,training_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "99P7yR2MYHhf",
    "outputId": "78af8c42-256b-4edb-adf0-1b637272bf69"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"The training results indicate a very low r2_score, suggesting that the model is not capturing the variance in the target variable effectively. The training history shows that the validation RMSE does not improve significantly, indicating potential overfitting or that the model is not learning effectively. To improve the model, consider the following: 1) Feature engineering to create more informative features. 2) Hyperparameter tuning, especially increasing 'n_estimators' and adjusting 'max_depth' and 'learning_rate'. 3) Try different model types like Random Forest or Neural Networks. 4) Use more advanced techniques like feature selection or dimensionality reduction to improve model performance.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(evaluator_suggestion.replace(\"```\", \"\").removeprefix(\"json\"))['reasoning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "zUlv-vnUaohX"
   },
   "outputs": [],
   "source": [
    "## Report agent\n",
    "\n",
    "class ReportAgent:\n",
    "\n",
    "  def __init__(self, model = 'gpt-4o',user_instructions = '', user_defined_target = ''):\n",
    "    self.model = model\n",
    "    self.name = 'Report Agent'\n",
    "    self.user_defined_target = user_defined_target\n",
    "    self.user_instructions = 'You are a data scientist specialized in summarizing the given information and generate a report.\\\n",
    "    You take in promblem statement, modeling proposal, training result, and model optimization suggestions.\\\n",
    "    Based on these information, you summarize the information and generate a report\\\n",
    "      '+user_instructions\n",
    "\n",
    "    if self.user_defined_target:\n",
    "      self.user_instructions += f'The target variable is {self.user_defined_target}'\n",
    "\n",
    "    self.agent = Agent(\n",
    "        name = self.name,\n",
    "        model = self.model,\n",
    "        instructions = self.user_instructions,\n",
    "        model_settings = ModelSettings(temperature = 0)\n",
    "        )\n",
    "\n",
    "  async def generate_report(\n",
    "        self,\n",
    "        problem_statement: str,\n",
    "        fea_eng_result: str,\n",
    "        model_proposal: str,\n",
    "        training_result: str,\n",
    "        optimization_suggestion: str = \"\"\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Generate a final full analysis report.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Generate a detailed professional analytical report based on the following inputs.\n",
    "\n",
    "        ### **Problem Statement**\n",
    "        {problem_statement}\n",
    "\n",
    "        ### **Variable Selection & Feature Engineering and rationale**\n",
    "        {fea_eng_result}\n",
    "\n",
    "        ### **Modeling Summary**\n",
    "        {model_proposal}\n",
    "\n",
    "        ### **Model Training Result**\n",
    "        {training_result}\n",
    "\n",
    "        ### **Model Optimization Suggestions**\n",
    "        {optimization_suggestion}\n",
    "\n",
    "        Format the report in structured markdown with:\n",
    "        - Executive summary\n",
    "        - Problem statement\n",
    "        - Variable selection and feature engineering and rationale\n",
    "        - Model selection and training methodology\n",
    "        - Model training and evaluation results\n",
    "        - Model Optimization Sggestions\n",
    "        \"\"\"\n",
    "\n",
    "        result = await Runner.run(self.agent, prompt)\n",
    "        print(result.final_output)\n",
    "        return result.final_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "iUinvKMaak9W"
   },
   "outputs": [],
   "source": [
    "report_agent = ReportAgent(user_instructions = problem_statement,user_defined_target =target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "RRxd8ui-Zmss"
   },
   "outputs": [],
   "source": [
    "optimization_suggestion = eval(evaluator_suggestion.replace(\"```\", \"\").removeprefix(\"json\"))['reasoning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEz718jXaqF0",
    "outputId": "33783857-6046-4425-aaca-afe305f72bd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Analytical Report\n",
      "\n",
      "## Executive Summary\n",
      "\n",
      "This report outlines the development of a predictive model aimed at forecasting excess returns and implementing a betting strategy to outperform the S&P 500, while maintaining a volatility constraint of 120%. The model leverages a combination of public market data and proprietary datasets to identify patterns often overlooked. Despite the initial model's low performance, several optimization strategies are proposed to enhance its predictive capabilities.\n",
      "\n",
      "## Problem Statement\n",
      "\n",
      "The objective is to build a model that predicts excess returns and includes a betting strategy designed to outperform the S&P 500, while adhering to a 120% volatility constraint. The model utilizes daily data that combines public market information with proprietary datasets to uncover hidden patterns.\n",
      "\n",
      "## Variable Selection & Feature Engineering and Rationale\n",
      "\n",
      "### Data Overview\n",
      "- **Dataset Size**: 8990 rows, 98 columns\n",
      "- **Target Variable**: `market_forward_excess_returns`\n",
      "\n",
      "### Selected Features\n",
      "- **Features**: `M*`, `E*`, `I*`, `P*`, `V*`, `S*`, `D*`\n",
      "- **Dropped Columns**: \n",
      "  - `date_id`: Identifier with no predictive value\n",
      "  - `forward_returns`: Not available in the test set\n",
      "  - `risk_free_rate`: Not available in the test set\n",
      "\n",
      "### Feature Engineering\n",
      "- **Standardization**: Applied to `E*`, `I*`, `V*`, `S*` to handle different scales.\n",
      "- **Log Transform**: Applied to `P*` to address skewed distributions.\n",
      "- **Missing Value Handling**: Imputation with mean for `E*`, `M*`, `I*`, `P*`, `V*`, `S*`.\n",
      "\n",
      "## Model Selection and Training Methodology\n",
      "\n",
      "### Model Type\n",
      "- **Task Type**: Regression\n",
      "- **Model**: XGBoost\n",
      "\n",
      "### Hyperparameters\n",
      "- `n_estimators`: 100\n",
      "- `max_depth`: 6\n",
      "- `learning_rate`: 0.1\n",
      "- `subsample`: 0.8\n",
      "- `colsample_bytree`: 0.8\n",
      "\n",
      "### Evaluation Protocol\n",
      "- **Cross-Validation**: Ensures model generalizability\n",
      "- **Train-Test Split Ratio**: 0.7:0.2:0.1\n",
      "- **Metrics**: Mean Squared Error (MSE), R² Score\n",
      "\n",
      "## Model Training and Evaluation Results\n",
      "\n",
      "- **Mean Squared Error**: 0.000123\n",
      "- **R² Score**: 0.0013\n",
      "\n",
      "The low R² score indicates that the model is not effectively capturing the variance in the target variable. The validation RMSE shows minimal improvement, suggesting potential overfitting or ineffective learning.\n",
      "\n",
      "## Model Optimization Suggestions\n",
      "\n",
      "1. **Feature Engineering**: Develop more informative features to enhance model input.\n",
      "2. **Hyperparameter Tuning**: \n",
      "   - Increase `n_estimators`\n",
      "   - Adjust `max_depth` and `learning_rate`\n",
      "3. **Alternative Models**: Consider Random Forest or Neural Networks for potentially better performance.\n",
      "4. **Advanced Techniques**: Implement feature selection or dimensionality reduction to improve model efficiency and accuracy.\n",
      "\n",
      "By addressing these areas, the model's performance can be significantly improved, leading to more accurate predictions and a more effective betting strategy.\n"
     ]
    }
   ],
   "source": [
    "report = await report_agent.generate_report(problem_statement, fea_eng_result, model_proposal, evaluation_result, optimization_suggestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "csMerEWEa7W9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
